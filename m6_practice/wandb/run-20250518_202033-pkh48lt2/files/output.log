Epoch 0, iter 0, loss: 2.2726244926452637
Epoch 0, iter 100, loss: 0.7308453917503357
Epoch 0, iter 200, loss: 0.7662143707275391
Epoch 0, iter 300, loss: 0.5703118443489075
Epoch 0, iter 400, loss: 0.44458428025245667
Epoch 0, iter 500, loss: 1.8669124841690063
Epoch 0, iter 600, loss: 0.5696938037872314
Epoch 0, iter 700, loss: 0.16171994805335999
Epoch 0, iter 800, loss: 0.1465950757265091
Epoch 0, iter 900, loss: 0.319879949092865
Epoch 1, iter 0, loss: 0.503844678401947
Epoch 1, iter 100, loss: 0.21117034554481506
Epoch 1, iter 200, loss: 0.5413438081741333
Epoch 1, iter 300, loss: 0.39611580967903137
Epoch 1, iter 400, loss: 0.12435609847307205
Epoch 1, iter 500, loss: 0.9434634447097778
Epoch 1, iter 600, loss: 0.3122687041759491
Epoch 1, iter 700, loss: 0.1954512596130371
Epoch 1, iter 800, loss: 0.22289246320724487
Epoch 1, iter 900, loss: 0.07949792593717575
Epoch 2, iter 0, loss: 0.22674186527729034
Epoch 2, iter 100, loss: 0.18857567012310028
Epoch 2, iter 200, loss: 0.22299699485301971
Epoch 2, iter 300, loss: 0.23051956295967102
Epoch 2, iter 400, loss: 0.18779531121253967
Epoch 2, iter 500, loss: 0.46742627024650574
Epoch 2, iter 600, loss: 0.2465338557958603
Epoch 2, iter 700, loss: 0.037192318588495255
Epoch 2, iter 800, loss: 0.1296188086271286
Epoch 2, iter 900, loss: 0.06491966545581818
/home/euna/miniconda3/envs/py310/lib/python3.10/site-packages/sklearn/utils/_plotting.py:25: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  _, ax = plt.subplots()
Epoch 3, iter 0, loss: 0.24401091039180756
Epoch 3, iter 100, loss: 0.08532948791980743
Epoch 3, iter 200, loss: 0.09201058745384216
Epoch 3, iter 300, loss: 0.13866256177425385
Epoch 3, iter 400, loss: 0.0738210529088974
Epoch 3, iter 500, loss: 0.43491941690444946
Epoch 3, iter 600, loss: 0.20012997090816498
Epoch 3, iter 700, loss: 0.02920166589319706
Epoch 3, iter 800, loss: 0.16168032586574554
Epoch 3, iter 900, loss: 0.024376193061470985
Epoch 4, iter 0, loss: 0.06400785595178604
Epoch 4, iter 100, loss: 0.1274581104516983
Epoch 4, iter 200, loss: 0.17444603145122528
Epoch 4, iter 300, loss: 0.12324012815952301
Epoch 4, iter 400, loss: 0.061130691319704056
Epoch 4, iter 500, loss: 0.4888733923435211
Epoch 4, iter 600, loss: 0.20106077194213867
Epoch 4, iter 700, loss: 0.040524858981370926
Epoch 4, iter 800, loss: 0.03691597655415535
Epoch 4, iter 900, loss: 0.015163509175181389
