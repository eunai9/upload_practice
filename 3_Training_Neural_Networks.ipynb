{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5f6449",
   "metadata": {},
   "source": [
    "## Losses in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e38c7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "operator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Define a transform to normalize the data\u001b[39;00m\n\u001b[32m      6\u001b[39m transform = transforms.Compose(\n\u001b[32m      7\u001b[39m     [\n\u001b[32m      8\u001b[39m         transforms.ToTensor(),\n\u001b[32m      9\u001b[39m         transforms.Normalize((\u001b[32m0.5\u001b[39m,), (\u001b[32m0.5\u001b[39m,)),\n\u001b[32m     10\u001b[39m     ],\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlops/lib/python3.11/site-packages/torchvision/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlops/lib/python3.11/site-packages/torchvision/_meta_registrations.py:163\u001b[39m\n\u001b[32m    153\u001b[39m     torch._check(\n\u001b[32m    154\u001b[39m         grad.dtype == rois.dtype,\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: (\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m         ),\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m grad.new_empty((batch_size, channels, height, width))\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;129m@torch\u001b[39m.library.register_fake(\u001b[33m\"\u001b[39m\u001b[33mtorchvision::nms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmeta_nms\u001b[39m(dets, scores, iou_threshold):\n\u001b[32m    165\u001b[39m     torch._check(dets.dim() == \u001b[32m2\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mboxes should be a 2d tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdets.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    166\u001b[39m     torch._check(dets.size(\u001b[32m1\u001b[39m) == \u001b[32m4\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mboxes should have 4 elements in dimension 1, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdets.size(\u001b[32m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlops/lib/python3.11/site-packages/torch/library.py:828\u001b[39m, in \u001b[36mregister_fake.<locals>.register\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    827\u001b[39m     use_lib = lib\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m use_lib._register_fake(op_name, func, _stacklevel=stacklevel + \u001b[32m1\u001b[39m)\n\u001b[32m    829\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlops/lib/python3.11/site-packages/torch/library.py:198\u001b[39m, in \u001b[36mLibrary._register_fake\u001b[39m\u001b[34m(self, op_name, fn, _stacklevel)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    196\u001b[39m     func_to_register = fn\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m handle = entry.fake_impl.register(func_to_register, source)\n\u001b[32m    199\u001b[39m \u001b[38;5;28mself\u001b[39m._registration_handles.append(handle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mlops/lib/python3.11/site-packages/torch/_library/fake_impl.py:31\u001b[39m, in \u001b[36mFakeImplHolder.register\u001b[39m\u001b[34m(self, func, source)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.kernel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     27\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.qualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malready has an fake impl registered at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.kernel.source\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     30\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._C._dispatch_has_kernel_for_dispatch_key(\u001b[38;5;28mself\u001b[39m.qualname, \u001b[33m\"\u001b[39m\u001b[33mMeta\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     33\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.qualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m     )\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._C._dispatch_has_kernel_for_dispatch_key(\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mself\u001b[39m.qualname, \u001b[33m\"\u001b[39m\u001b[33mCompositeImplicitAutograd\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m ):\n",
      "\u001b[31mRuntimeError\u001b[39m: operator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ],\n",
    ")\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(\"~/.pytorch/MNIST_data/\", download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7dfa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3047, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2762, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10), nn.LogSoftmax(dim=1))\n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "### Run this to check your work\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10279175",
   "metadata": {},
   "source": [
    "## Autograd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5072, 1.9234],\n",
      "        [0.0815, 1.4944]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2573, 3.6994],\n",
      "        [0.0066, 2.2332]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f3cb420ef50>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a32b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5491, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac212220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2536, 0.9617],\n",
      "        [0.0408, 0.7472]])\n",
      "tensor([[0.2536, 0.9617],\n",
      "        [0.0408, 0.7472]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(2 * x / torch.numel(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5da1ec",
   "metadata": {},
   "source": [
    "## Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0021,  0.0021,  0.0021,  ...,  0.0021,  0.0021,  0.0021],\n",
      "        [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
      "        [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before backward pass: \\n\", model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"After backward pass: \\n\", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828ff59",
   "metadata": {},
   "source": [
    "## Training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78a7f152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0271, -0.0034,  0.0091,  ...,  0.0349, -0.0027, -0.0252],\n",
      "        [-0.0322, -0.0232, -0.0256,  ...,  0.0073,  0.0304, -0.0209],\n",
      "        [-0.0232,  0.0309,  0.0314,  ...,  0.0326, -0.0052,  0.0186],\n",
      "        ...,\n",
      "        [-0.0213,  0.0322,  0.0149,  ..., -0.0302,  0.0339,  0.0168],\n",
      "        [ 0.0334, -0.0277, -0.0090,  ...,  0.0075, -0.0044,  0.0138],\n",
      "        [-0.0298,  0.0242,  0.0016,  ..., -0.0182, -0.0073,  0.0222]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-3.9921e-05, -3.9921e-05, -3.9921e-05,  ..., -3.9921e-05,\n",
      "         -3.9921e-05, -3.9921e-05],\n",
      "        [-1.3228e-04, -1.3228e-04, -1.3228e-04,  ..., -1.3228e-04,\n",
      "         -1.3228e-04, -1.3228e-04],\n",
      "        [ 2.0258e-03,  2.0258e-03,  2.0258e-03,  ...,  2.0258e-03,\n",
      "          2.0258e-03,  2.0258e-03],\n",
      "        ...,\n",
      "        [-7.7204e-04, -7.7204e-04, -7.7204e-04,  ..., -7.7204e-04,\n",
      "         -7.7204e-04, -7.7204e-04],\n",
      "        [-4.4808e-03, -4.4808e-03, -4.4808e-03,  ..., -4.4808e-03,\n",
      "         -4.4808e-03, -4.4808e-03],\n",
      "        [-2.9828e-03, -2.9828e-03, -2.9828e-03,  ..., -2.9828e-03,\n",
      "         -2.9828e-03, -2.9828e-03]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial weights - \", model[0].weight)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print(\"Gradient -\", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0271, -0.0034,  0.0091,  ...,  0.0349, -0.0027, -0.0252],\n",
      "        [-0.0322, -0.0232, -0.0256,  ...,  0.0073,  0.0304, -0.0209],\n",
      "        [-0.0232,  0.0309,  0.0314,  ...,  0.0325, -0.0052,  0.0186],\n",
      "        ...,\n",
      "        [-0.0213,  0.0322,  0.0149,  ..., -0.0302,  0.0339,  0.0168],\n",
      "        [ 0.0334, -0.0277, -0.0090,  ...,  0.0075, -0.0043,  0.0139],\n",
      "        [-0.0297,  0.0242,  0.0016,  ..., -0.0182, -0.0073,  0.0223]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and view the new weights\n",
    "optimizer.step()\n",
    "print(\"Updated weights - \", model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b806a",
   "metadata": {},
   "source": [
    "## Training for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e522db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.308278787873193\n",
      "Training loss: 2.308262900248774\n",
      "Training loss: 2.3082751973605613\n",
      "Training loss: 2.3082752692928192\n"
     ]
    }
   ],
   "source": [
    "## Your solution here\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for _ in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:  # noqa: B007\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27039543",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import helper\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab09b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
