{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5f6449",
   "metadata": {},
   "source": [
    "## Losses in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e38c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ],\n",
    ")\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST(\"~/.pytorch/MNIST_data/\", download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee7dfa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3047, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10))\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2762, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 10), nn.LogSoftmax(dim=1))\n",
    "\n",
    "# TODO: Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "### Run this to check your work\n",
    "# Get our data\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10279175",
   "metadata": {},
   "source": [
    "## Autograd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5072, 1.9234],\n",
      "        [0.0815, 1.4944]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2573, 3.6994],\n",
      "        [0.0066, 2.2332]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x7f3cb420ef50>\n"
     ]
    }
   ],
   "source": [
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a32b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5491, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac212220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2536, 0.9617],\n",
      "        [0.0408, 0.7472]])\n",
      "tensor([[0.2536, 0.9617],\n",
      "        [0.0408, 0.7472]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(2 * x / torch.numel(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5da1ec",
   "metadata": {},
   "source": [
    "## Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        [-0.0016, -0.0016, -0.0016,  ..., -0.0016, -0.0016, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0021,  0.0021,  0.0021,  ...,  0.0021,  0.0021,  0.0021],\n",
      "        [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018],\n",
      "        [-0.0018, -0.0018, -0.0018,  ..., -0.0018, -0.0018, -0.0018]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Before backward pass: \\n\", model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"After backward pass: \\n\", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f828ff59",
   "metadata": {},
   "source": [
    "## Training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "# Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78a7f152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0271, -0.0034,  0.0091,  ...,  0.0349, -0.0027, -0.0252],\n",
      "        [-0.0322, -0.0232, -0.0256,  ...,  0.0073,  0.0304, -0.0209],\n",
      "        [-0.0232,  0.0309,  0.0314,  ...,  0.0326, -0.0052,  0.0186],\n",
      "        ...,\n",
      "        [-0.0213,  0.0322,  0.0149,  ..., -0.0302,  0.0339,  0.0168],\n",
      "        [ 0.0334, -0.0277, -0.0090,  ...,  0.0075, -0.0044,  0.0138],\n",
      "        [-0.0298,  0.0242,  0.0016,  ..., -0.0182, -0.0073,  0.0222]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[-3.9921e-05, -3.9921e-05, -3.9921e-05,  ..., -3.9921e-05,\n",
      "         -3.9921e-05, -3.9921e-05],\n",
      "        [-1.3228e-04, -1.3228e-04, -1.3228e-04,  ..., -1.3228e-04,\n",
      "         -1.3228e-04, -1.3228e-04],\n",
      "        [ 2.0258e-03,  2.0258e-03,  2.0258e-03,  ...,  2.0258e-03,\n",
      "          2.0258e-03,  2.0258e-03],\n",
      "        ...,\n",
      "        [-7.7204e-04, -7.7204e-04, -7.7204e-04,  ..., -7.7204e-04,\n",
      "         -7.7204e-04, -7.7204e-04],\n",
      "        [-4.4808e-03, -4.4808e-03, -4.4808e-03,  ..., -4.4808e-03,\n",
      "         -4.4808e-03, -4.4808e-03],\n",
      "        [-2.9828e-03, -2.9828e-03, -2.9828e-03,  ..., -2.9828e-03,\n",
      "         -2.9828e-03, -2.9828e-03]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial weights - \", model[0].weight)\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this because gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Forward pass, then backward pass, then update weights\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print(\"Gradient -\", model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0271, -0.0034,  0.0091,  ...,  0.0349, -0.0027, -0.0252],\n",
      "        [-0.0322, -0.0232, -0.0256,  ...,  0.0073,  0.0304, -0.0209],\n",
      "        [-0.0232,  0.0309,  0.0314,  ...,  0.0325, -0.0052,  0.0186],\n",
      "        ...,\n",
      "        [-0.0213,  0.0322,  0.0149,  ..., -0.0302,  0.0339,  0.0168],\n",
      "        [ 0.0334, -0.0277, -0.0090,  ...,  0.0075, -0.0043,  0.0139],\n",
      "        [-0.0297,  0.0242,  0.0016,  ..., -0.0182, -0.0073,  0.0223]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Take an update step and view the new weights\n",
    "optimizer.step()\n",
    "print(\"Updated weights - \", model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b806a",
   "metadata": {},
   "source": [
    "## Training for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e522db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.308278787873193\n",
      "Training loss: 2.308262900248774\n",
      "Training loss: 2.3082751973605613\n",
      "Training loss: 2.3082752692928192\n"
     ]
    }
   ],
   "source": [
    "## Your solution here\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 10),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "for _ in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:  # noqa: B007\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "\n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27039543",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import helper\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "ps = torch.exp(logps)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ab09b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlops)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
